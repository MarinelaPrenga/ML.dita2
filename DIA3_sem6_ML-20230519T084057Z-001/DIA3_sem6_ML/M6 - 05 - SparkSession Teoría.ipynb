{"cells":[{"cell_type":"markdown","metadata":{"id":"XGV-KL6pL1nE"},"source":["# SparkSession vs SparkContext"]},{"cell_type":"markdown","metadata":{"id":"_KYu3hrML1nG"},"source":["## Importamos SparkContext y SparkSession"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6T70QOZhL1nH","executionInfo":{"status":"ok","timestamp":1684481799310,"user_tz":-120,"elapsed":6429,"user":{"displayName":"Marinela Prenga","userId":"04354016761013613871"}}},"outputs":[],"source":["!pip install pyspark --quiet\n","from pyspark import SparkContext\n","from pyspark.sql import SparkSession"]},{"cell_type":"markdown","metadata":{"id":"chASV6-OL1nI"},"source":["## Creamos nuestra primera sesion"]},{"cell_type":"markdown","source":["En Apache Spark, una **sesión es una conexión de un cliente con el cluster Spark**. La sesión se utiliza para enviar trabajos al cluster y obtener resultados de ellos. Una sesión se puede iniciar de forma interactiva desde la línea de comandos o programáticamente desde una aplicación de Spark.\n","\n","Un **contexto de Spark** es un objeto que representa una conexión a un cluster Spark y proporciona un punto de acceso a todas las funcionalidades de Spark. En una aplicación de Spark, normalmente se crea un contexto al principio del programa y se utiliza para realizar todas las operaciones de Spark en esa aplicación. Por ejemplo, podrías utilizar un contexto para crear un conjunto de datos (RDD), aplicar transformaciones y acciones sobre él y obtener resultados.\n","\n","Es importante mencionar que **una sesión puede tener múltiples contextos**, y que cada contexto se puede utilizar para realizar operaciones de Spark de forma independiente. Por ejemplo, podrías tener un contexto para procesar datos en tiempo real y otro contexto para realizar análisis en lote."],"metadata":{"id":"WrkEikPTe4Bu"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"HKjXd8P6L1nI","executionInfo":{"status":"ok","timestamp":1684481791900,"user_tz":-120,"elapsed":9619,"user":{"displayName":"Marinela Prenga","userId":"04354016761013613871"}}},"outputs":[],"source":["#Convenio\n","#Sesión --> spark\n","#Contexto --> sc\n","\n","spark = SparkSession.builder \\\n","        .master(\"local\") \\\n","        .appName(\"miPrimerApplicacion\") \\\n","        .getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"F3614c6xL1nI"},"source":["## Terminamos la sesión actual\n","\n","No podemos tener mas de una sesión a la vez en nuestro notebook, por lo cual con el método 'stop' terminaremos la applicación.\n","\n","De la misma forma, al terminar una applicación, debemos de indicar explicitamente que termine. De otra forma no liberará los recursos asignados."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R3iVqN4pL1nJ","executionInfo":{"status":"ok","timestamp":1684481800419,"user_tz":-120,"elapsed":736,"user":{"displayName":"Marinela Prenga","userId":"04354016761013613871"}}},"outputs":[],"source":["spark.stop()"]},{"cell_type":"markdown","metadata":{"id":"Dl01ZDfnL1nJ"},"source":["## Creamos una sesión heredando los atributos de un contexto"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"NhQR5VG1L1nK","executionInfo":{"status":"ok","timestamp":1684481810910,"user_tz":-120,"elapsed":1987,"user":{"displayName":"Marinela Prenga","userId":"04354016761013613871"}}},"outputs":[],"source":["sc = SparkContext(master=\"local\",appName = \"miPrimerContexto\")\n","spark2 = SparkSession(sc)"]},{"cell_type":"code","source":["spark2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"8Gsb4FRtQhpo","executionInfo":{"status":"ok","timestamp":1684481815762,"user_tz":-120,"elapsed":2420,"user":{"displayName":"Marinela Prenga","userId":"04354016761013613871"}},"outputId":"42954e5d-27e7-4046-b1e0-32c25be1f168"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff6f8459b40>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://a89f8804c028:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>miPrimerContexto</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"nD83MOvNL1nL"},"source":["## Creamos una sesión múltiple"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VO00IauNL1nL"},"outputs":[],"source":["sparkSession2 = spark2.newSession()"]},{"cell_type":"markdown","metadata":{"id":"2Hzhe1urL1nL"},"source":["## Revisamos que los tres objetos apuntan a la misma aplicación\n","\n","Aprovechando la salida que nos ofrece, conocemos SparkUI, el monitor por excelencia para Spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QKY6nAKL1nM"},"outputs":[],"source":["spark2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehCs3bdfL1nN"},"outputs":[],"source":["sparkSession2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LAqMi_scL1nN"},"outputs":[],"source":["spark2.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"https://github.com/terranigmark/curso-apache-spark-platzi/blob/master/1.%20Jupyter%20vs%20CLI.ipynb","timestamp":1672137901465}]}},"nbformat":4,"nbformat_minor":0}